from bs4 import BeautifulSoup
import requests
import csv
import jaconv
import re
import json
import csv
import time
import datetime
from normalize_japanese_addresses import normalize
import numpy as np

f = open("urls.txt", "r")

data = ['timestamp', 'storename', 'address_original', 'address_normalize[0]', 'address_normalize[1]', 'æœ€çµ‚æ›´æ–°æ—¥', 'url',
        'é–‹è¨­è€…ç¨®åˆ¥', 'é–‹è¨­è€…å', 'ç®¡ç†è€…å', 'æ­¯ç§‘ä¸€èˆ¬é ˜åŸŸä¸€è¦§', 'æ­¯ç§‘å£è…”å¤–ç§‘é ˜åŸŸä¸€è¦§', 'å°å…æ­¯ç§‘é ˜åŸŸä¸€è¦§', 'çŸ¯æ­£æ­¯ç§‘é ˜åŸŸä¸€è¦§',
        'æ–½è¨­çŠ¶æ³ä¸€è¦§', 'å¯¾å¿œå¯èƒ½ï¾…éº»é…”æ²»ç™‚ä¸€è¦§', 'åœ¨å®…åŒ»ç™‚', 'é€£æºï¾‰æœ‰ç„¡', 'æ­¯ç§‘åŒ»å¸«(ç·æ•°|å¸¸å‹¤|éå¸¸å‹¤)', 'æ­¯ç§‘æŠ€å·¥å£«(ç·æ•°|å¸¸å‹¤|éå¸¸å‹¤)',
        'æ­¯ç§‘åŠ©æ‰‹(ç·æ•°|å¸¸å‹¤|éå¸¸å‹¤)', 'æ­¯ç§‘è¡›ç”Ÿå£«(ç·æ•°|å¸¸å‹¤|éå¸¸å‹¤)', 'å‰å¹´åº¦1æ—¥å¹³å‡å¤–æ¥æ‚£è€…æ•°', 'ç·¯åº¦', 'çµŒåº¦', 'page', 'è¨ºç™‚ç§‘']

fc = open('iwate.csv', 'a', newline='', encoding='utf-8')
# Create a CSV writer object
writer = csv.writer(fc)
# Write the data to the CSV file
writer.writerow(data)


# Functions

# Functions  predefined
# -------------------------------------------------------------------------------------
def _normalization(arg):
    """
    æ–‡å­—åˆ—ã®æ­£è¦åŒ–ã‚’è¡Œã†å†…éƒ¨é–¢æ•°ã€‚
    ã²ã‚‰ãŒãªã‚’ã‚«ã‚¿ã‚«ãƒŠã«ã€å…¨è§’ã‚’åŠè§’ã«ã€å¤§æ–‡å­—ã‚’å°æ–‡å­—ã«å¤‰æ›ã—ã€ä¸å¯è¦–æ–‡å­—ã‚‚å‰Šé™¤ã™ã‚‹ã€‚
    """

    try:
        # ã²ã‚‰ãŒãªã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›
        try:
            result = jaconv.hira2kata(arg)
        except AttributeError:
            result = arg

        # å…¨è§’ã‚’åŠè§’ã«å¤‰æ›
        try:
            result = jaconv.z2h(result, digit=True, ascii=True)
        except AttributeError:
            result = result

        # å¤§æ–‡å­—ã‚’å°æ–‡å­—ã«å¤‰æ›
        try:
            result = result.lower()
        except AttributeError:
            result = result

        # ã‚¹ãƒšãƒ¼ã‚¹ã¨ä¸å¯è¦–æ–‡å­—ã‚’å‰Šé™¤
        try:
            result = _str_clean(result)
        except TypeError:
            result = result

    except:
        result = arg

    return result

# -------------------------------------------------------------------------------------


def normalization(arg):
    # print(2, arg)
    """
    æ–‡å­—åˆ—ã¾ãŸã¯æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã‚’æ­£è¦åŒ–ã™ã‚‹ã€‚
    """

    # å†…éƒ¨é–¢æ•°ã‚’NumPyã®ufuncã«å¤‰æ›
    _func = np.frompyfunc(_normalization, 1, 1)

    # ãƒªã‚¹ãƒˆã‚’NumPyé…åˆ—ã«å¤‰æ›
    _list = np.array(arg, dtype="object")

    # çµæœã‚’å–å¾—
    result = _func(_list)

    # ãƒ‡ãƒ¼ã‚¿å‹ã‚’å¤‰æ›
    result = result if type(result) == str else result.tolist() if type(
        result) == np.ndarray else "error"

    return result

# -------------------------------------------------------------------------------------


def _str_clean(arg):
    """
    æ–‡å­—åˆ—ã®ã‚¹ãƒšãƒ¼ã‚¹ã¨ä¸å¯è¦–æ–‡å­—ã‚’å‰Šé™¤ã™ã‚‹å†…éƒ¨é–¢æ•°ã€‚
    """

    try:
        result = arg.strip()
    except:
        result = arg

    try:
        result = re.sub(r"\r|\n|\r\n|\u3000|\t|ã€€| |,", " ", result)
    except TypeError:
        result = result

    return result

# -------------------------------------------------------------------------------------


def str_clean(arg):
    """
    æ–‡å­—åˆ—ã¾ãŸã¯æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã®ã‚¹ãƒšãƒ¼ã‚¹ã¨ä¸å¯è¦–æ–‡å­—ã‚’å‰Šé™¤ã™ã‚‹ã€‚
    """

    # å†…éƒ¨é–¢æ•°ã‚’NumPyã®ufuncã«å¤‰æ›
    _func = np.frompyfunc(_str_clean, 1, 1)

    # ãƒªã‚¹ãƒˆã‚’NumPyé…åˆ—ã«å¤‰æ›
    _list = np.array(arg, dtype="object")

    # çµæœã‚’å–å¾—
    result = _func(_list)

    # ãƒ‡ãƒ¼ã‚¿å‹ã‚’å¤‰æ›
    result = result if type(result) == str else result.tolist() if type(
        result) == np.ndarray else "error"

    return result

# -------------------------------------------------------------------------------------


def _split_buildingName(arg):
    # print(1, arg)
    """
    å»ºç‰©åã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹å†…éƒ¨é–¢æ•°ã€‚
    """
    # ãƒã‚¤ãƒ•ãƒ³ã®ä¸€èˆ¬åŒ–
    address = normalization(arg)
    hyphens = '-Ë—á…³á­¸â€â€‘â€’â€“â€”â€•âƒâ»âˆ’â–¬â”€â”â–ãƒ¼ã…¡ï¹˜ï¹£ï¼ï½°ğ„ğ†‘áš€'
    address = re.sub("|".join(hyphens), "-", address)
    address = re.sub(r"([ï½±-ï¾])(-)", r"\1ï½°", address)

    # ä¸ç›®ã€ç•ªåœ°ã€å·ãªã©ã§ä½¿ã‚ã‚Œã‚‹æ¼¢å­—ã®å®šç¾©
    chome_poplist = ["ï¾‰åˆ‡", "ç”ºç›®", "åœ°å‰²", "ä¸ç›®", "ä¸", "çµ„",
                     "ç•ªç”º", "ç•ªåœ°", "ç•ªç›®", "ç•ª", "å·å®¤", "å·", "è¡—åŒº", "ç”»åœ°"]
    chome_popset = r"|".join(chome_poplist)
    chome_holdlist = ["æ¡æ±", "æ¡è¥¿", "æ¡å—", "æ¡åŒ—", "æ¡é€š", "æ¡", "æ±", "è¥¿", "å—", "åŒ—"]
    chome_holdset = r"|".join(chome_holdlist)
    chome_alllist = chome_popset + chome_holdset
    chome_allset = r"|".join(chome_alllist)

    # separate address
    result = re.findall(re.compile(
        f"(.*\d\[{chome_allset}\]*)|(\D+\[-\d\]+)|(.*)"), address)

    # convert kanji into hyphen
    result = [[re.sub(f"(\d+)({chome_popset})", r"\1-", "".join(t))
               for t in tl] for tl in result]

    # concat all
    result = ["".join(t) for t in result]
    result = "".join(result)

    # special case handling (1ï¾‰3 1åŒº1)
    result = re.sub(r"([^ï½±ï½°ï¾])(ï¾‰|ï½°)(\d)", r"\1-\3", result)
    result = re.sub(r"(\d)(åŒº)(\d)", r"\1-\3", result)
    result = re.sub("--", "-", result)

    # separate into [japanese] + [number + hyphen] chunks
    result = re.findall(re.compile(
        f"(\D+[-\d]+[{chome_holdset}]*[-\d]+)|(\D+[-\d]+)|(.*)"), result)
    result = [t for t in ["".join(tl) for tl in result] if t != ""]
    # print(3, result)
    # merge [number + hyphen] chunks
    try:
        result = [result[0]] + ["".join(result[1:])]
    except:
        result = result

    # 2åˆ—ç›®ãŒå˜ç‹¬ã€Œf, éšã€ã®ã¨ãã€1åˆ—ç›®ã®æœ«å°¾æ•°ã‚’2åˆ—ç›®ã¸ç§»å‹•
    if re.fullmatch(r"f|éš", result[1]):
        result[1] = "".join(re.compile(r"\d+$").findall(result[0])) + result[1]
        result[0] = re.sub(r"\d+$", "", result[0])

    # 2åˆ—ç›®ã§ã€éšæ•°ãŒç•ªåœ°ã¨çµåˆã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã¨ãã€éšæ•°ã‚’1æ¡ã¨ã¿ãªã—ã€æ®‹ã‚Šã®æ•°å­—ã‚’ç•ªåœ°ã¨ã—ã¦1åˆ—ç›®ã¸ç§»å‹•
    if (re.fullmatch(r"\D+", result[0]) or re.search(r"-$", result[0])) and re.match(r"(\d*)(\d)(f|éš)(\d*)", result[1]):
        result[1] = re.sub(r"(\d*)(\d)(f|éš)(\d*)", r"\1,\2\3\4", result[1])
        result[0] = result[0] + result[1][:result[1].find(",")]
        result[1] = result[1][result[1].find(",")+1:]

    # æœ«å°¾ã®ãƒã‚¤ãƒ•ãƒ³ã‚’å‰Šé™¤
    result[0] = re.sub(r"-+$", "", result[0])

    return result


def get_page(url, category):
    response = requests.get(url.replace('detail2', category))
    return response


def get_soup(html):
    soup = BeautifulSoup(html, 'lxml')
    return soup


def get_base_data(html):
    soup = get_soup(html)
    timeStamp = datetime.date.today()
    baseData = {
        'updated_at': soup.find('td', {"class": "scel0"}).find('b').text,
        'timestamp': timeStamp
    }
    table_items = soup.find('table', {"class": "stabl2"}).findAll(
        'table', {"class": "stabl3"})
    baseData['storename'] = table_items[0].findAll('tr')[1].find(
        'td', {"class": "scel4"}).find('b').text.replace('\u3000', ' ')
    baseData['founder_name'] = table_items[1].findAll('tr')[2].find(
        'td', {"class": "scel4"}).text.replace('\u3000', ' ')
    baseData['founder_type'] = table_items[1].findAll('tr')[3].find(
        'td', {"class": "scel4"}).text.replace('\u3000', ' ')
    baseData['admin_name'] = table_items[2].findAll('tr')[2].find(
        'td', {"class": "scel4"}).text.replace('\u3000', ' ')
    baseData['address'] = table_items[3].findAll('tr')[3].find(
        'td', {"class": "scel4"}).text.strip()
    try:
        storeAddressNormalize = "".join(
            list(normalize(baseData['address']).values())[0:4])
        baseData['address_normalize_1'] = _split_buildingName(storeAddressNormalize)[
            0]
        baseData['address_normalize_2'] = _split_buildingName(storeAddressNormalize)[
            1]
    except:
        baseData['address_normalize_1'] = baseData['address_normalize_2'] = "na"
    # print(baseData)
    return baseData


def get_department_data(html):
    soup = get_soup(html)
    table_elements = soup.find('table', {"class": "stabl2"}).findAll(
        'table', {"class": "stabl3"})
    departmentData = []
    for td_el in table_elements[0].findAll('td', {"class", "scel4"}):
        if td_el.text == '\u3000':
            break
        departmentData.append(td_el.text)
    # print(departmentData)
    return departmentData


def get_service_data(html):
    soup = get_soup(html)
    table_elements = soup.find('table', {"class": "stabl2"}).findAll(
        'table', {"class": "stabl3"})
    serviceData = []
    if table_elements[0].find('td', {"class": "scel4"}).text.strip() == 'æœ‰':
        serviceData.append(table_elements[0].find(
            'td', {"class": "scel3"}).text.strip())
    if table_elements[2].find('td', {"class": "scel4"}).find('img') is not None:
        serviceData.append(
            'éšœãŒã„è€…ã«å¯¾ã™ã‚‹é…æ…®('+table_elements[2].find('td', {"class": "scel4"}).text.strip().replace('\n', ',').replace('\xa0', ' ')+')')
    if table_elements[3].find('td', {"class": "scel4"}).find('img') is not None:
        serviceData.append(
            'è»Šæ¤…å­åˆ©ç”¨è€…ã«å¯¾ã™ã‚‹é…æ…®('+table_elements[3].find('td', {"class": "scel4"}).text.strip().replace('\n', ',').replace('\xa0', ' ')+')')
    if table_elements[4].find('td', {"class": "scel4"}).find('img') is not None:
        serviceData.append(table_elements[4].find(
            'td', {"class": "scel4"}).text.strip().replace('\n', ',').replace('\xa0', ' '))
    print('service', serviceData)
    return serviceData if len(serviceData) > 0 else 'na'


def get_general_data(html):
    soup = get_soup(html)
    table_elements = soup.find("table", {"class", "stabl2"}).findAll(
        "table", {"class", "stabl3"})
    generalData = {}
    total = table_elements[5].findAll('td', {"class": "scel4"})
    homecare_element = table_elements[5].find('td', string='åœ¨å®…åŒ»ç™‚')
    collaboration_element = table_elements[5].find('td', string='é€£æºã®æœ‰ç„¡')
    collaboration = []
    homecare = []
    if homecare_element is None:
        if collaboration_element is None:
            collaboration = 'na'
        else:
            for t in total:
                collaboration.append(t.text)
        homecare = 'na'
    else:
        if collaboration_element is None:
            for t in total:
                homecare.append(t.text)
            collaboration = 'na'
        else:
            table_string = str(table_elements[5])
            htd_elements = table_string.split(
                '<td class="scel3"')[2].split('<td')
            for htd_el in htd_elements[1:]:
                homecare.append(htd_el.split('</td>')
                                [0].split('>')[1])
            ctd_elements = table_string.split(
                '<td class="scel3"')[3].split('<td')
            for ctd_el in ctd_elements[1:]:
                collaboration.append(ctd_el.split(
                    '</td>')[0].split('>')[1])
    generalData['homecare'] = homecare
    generalData['collaboration'] = collaboration

    dentist_element = table_elements[7].find('td', string='æ­¯ç§‘åŒ»å¸«')
    hygienist_element = table_elements[7].find('td', string='æ­¯ç§‘è¡›ç”Ÿå£«')
    tech_element = table_elements[7].find('td', string='æ­¯ç§‘æŠ€å·¥å£«')
    if not dentist_element is None:
        den_total = dentist_element.find_next_sibling(
            'td').text.strip().split(' äºº')[0]
        generalData['dentist'] = den_total+'|' + '-' + \
            '|' + '-' if den_total != '' else 'na'
    else:
        generalData['dentist'] = 'na'
    if not hygienist_element is None:
        hyg_total = hygienist_element.find_next_sibling(
            'td').text.strip().split(' äºº')[0]
        generalData['hygienist'] = hyg_total+'|' + \
            '-' + '|' + '-' if hyg_total != '' else 'na'
    else:
        generalData['hygienist'] = 'na'
    if not tech_element is None:
        tech_total = tech_element.find_next_sibling(
            'td').text.strip().split(' äºº')[0]
        generalData['tech'] = tech_total+'|' + '-' + \
            '|' + '-' if tech_total != '' else 'na'
    else:
        generalData['tech'] = 'na'

    print(generalData)

    return generalData


def get_professional_data(html):
    soup = get_soup(html)
    table_elements = soup.find("table", {"class", "stabl2"}).findAll(
        "table", {"class", "stabl3"})
    professionalData = {}
    total = table_elements[4].findAll('td', {"class": "scel4"})
    dental_element = table_elements[4].find('td', string='æ­¯ç§‘é ˜åŸŸ')
    oral_element = table_elements[4].find('td', string='å£è…”å¤–ç§‘é ˜åŸŸ')
    dental = []
    oral = []
    if dental_element is None:
        if oral_element is None:
            oral = 'na'
        else:
            for t in total:
                oral.append(t.text)
        dental = 'na'
    else:
        if oral_element is None:
            for t in total:
                dental.append(t.text)
            oral = 'na'
        else:
            table_string = str(table_elements[4])
            dtd_elements = table_string.split(
                '<td class="scel3"')[2].split('<td class="scel4"')
            for dtd_el in dtd_elements[1:]:
                dental.append(dtd_el.split('</td>')
                              [0].split('>')[1])
            otd_elements = table_string.split(
                '<td class="scel3"')[3].split('<td class="scel4"')
            for otd_el in otd_elements[1:]:
                oral.append(otd_el.split('</td>')
                            [0].split('>')[1])
    professionalData['dental'] = dental
    professionalData['oral'] = oral

    day_patients = soup.find('td', string='å‰å¹´åº¦1æ—¥å¹³å‡æ‚£è€…æ•°').find_parent(
        'tr').find_next_sibling('tr').find('td').text.strip()
    professionalData['day_patients'] = day_patients.split(
        ' äºº')[0] if day_patients != '' else 'na'
    print(professionalData)

    return professionalData


def main():
    for line in f:
        page = line.split(',')[0]
        url = line.split(',')[1]
        print(url)
        data = {}
        # url = 'http://www.med-info.pref.iwate.jp/imin/kikan/show-shika-detail2.do?f.kikanCd=03300431&by='
        baseInfo = get_page(url, 'detail1')
        if baseInfo.status_code == 200:
            baseData = get_base_data(baseInfo.text)

        departmentInfo = get_page(url, 'detail2')
        if departmentInfo.status_code == 200:
            departmentData = get_department_data(departmentInfo.text)

        serviceInfo = get_page(url, 'detail5')
        if serviceInfo.status_code == 200:
            serviceData = get_service_data(serviceInfo.text)

        generalInfo = get_page(url, 'detail6')
        if generalInfo.status_code == 200:
            generalData = get_general_data(generalInfo.text)

        professionalInfo = get_page(url, 'detail7')
        if professionalInfo.status_code == 200:
            professionalData = get_professional_data(professionalInfo.text)

        data = [
            baseData['timestamp'],
            baseData['storename'],
            baseData['address'],
            baseData['address_normalize_1'],
            baseData['address_normalize_2'],
            baseData['updated_at'],
            url,
            baseData['founder_type'],
            baseData['founder_name'],
            baseData['admin_name'],
            professionalData['dental'],
            professionalData['oral'],
            'na',
            'na',
            serviceData,
            'na',
            generalData['homecare'],
            generalData['collaboration'],
            generalData['dentist'],
            generalData['tech'],
            'na',
            generalData['hygienist'],
            professionalData['day_patients'],
            'na',
            'na',
            page,
            departmentData
        ]
        writer.writerow(data)

    fc.close()


if __name__ == '__main__':
    main()
