import requests
import time
import csv
import jaconv
import re
import json
import datetime
from dateutil.parser import parse
from normalize_japanese_addresses import normalize
import numpy as np
import builtins

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.chrome.service import Service
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager


WAIT_SEC = 20

f = open("urls_test.txt", "r")

data = ['timestamp', 'storename', 'address_original', 'address_normalize[0]', 'address_normalize[1]', 'æœ€çµ‚æ›´æ–°æ—¥', 'url',
        'é–‹è¨­è€…ç¨®åˆ¥', 'é–‹è¨­è€…å', 'ç®¡ç†è€…å', 'æ­¯ç§‘ä¸€èˆ¬é ˜åŸŸä¸€è¦§', 'æ­¯ç§‘å£è…”å¤–ç§‘é ˜åŸŸä¸€è¦§', 'å°å…æ­¯ç§‘é ˜åŸŸä¸€è¦§', 'çŸ¯æ­£æ­¯ç§‘é ˜åŸŸä¸€è¦§',
        'æ–½è¨­çŠ¶æ³ä¸€è¦§', 'å¯¾å¿œå¯èƒ½ï¾…éº»é…”æ²»ç™‚ä¸€è¦§', 'åœ¨å®…åŒ»ç™‚', 'é€£æºï¾‰æœ‰ç„¡', 'æ­¯ç§‘åŒ»å¸«(ç·æ•°|å¸¸å‹¤|éžå¸¸å‹¤)', 'æ­¯ç§‘æŠ€å·¥å£«(ç·æ•°|å¸¸å‹¤|éžå¸¸å‹¤)',
        'æ­¯ç§‘åŠ©æ‰‹(ç·æ•°|å¸¸å‹¤|éžå¸¸å‹¤)', 'æ­¯ç§‘è¡›ç”Ÿå£«(ç·æ•°|å¸¸å‹¤|éžå¸¸å‹¤)', 'å‰å¹´åº¦1æ—¥å¹³å‡å¤–æ¥æ‚£è€…æ•°', 'ç·¯åº¦', 'çµŒåº¦', 'page', 'è¨ºç™‚ç§‘']

fc = open('yamanashi.csv', 'a', newline='', encoding='utf-8')
# Create a CSV writer object
writer = csv.writer(fc)
# Write the data to the CSV file
writer.writerow(data)


###  Functions

## Functions  predefined
# -------------------------------------------------------------------------------------
def _normalization(arg):
    """
    æ–‡å­—åˆ—ã®æ­£è¦åŒ–ã‚’è¡Œã†å†…éƒ¨é–¢æ•°ã€‚
    ã²ã‚‰ãŒãªã‚’ã‚«ã‚¿ã‚«ãƒŠã«ã€å…¨è§’ã‚’åŠè§’ã«ã€å¤§æ–‡å­—ã‚’å°æ–‡å­—ã«å¤‰æ›ã—ã€ä¸å¯è¦–æ–‡å­—ã‚‚å‰Šé™¤ã™ã‚‹ã€‚
    """

    try:
        # ã²ã‚‰ãŒãªã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›
        try:
            result = jaconv.hira2kata(arg)
        except AttributeError:
            result = arg

        # å…¨è§’ã‚’åŠè§’ã«å¤‰æ›
        try:
            result = jaconv.z2h(result, digit=True, ascii=True)
        except AttributeError:
            result = result

        # å¤§æ–‡å­—ã‚’å°æ–‡å­—ã«å¤‰æ›
        try:
            result = result.lower()
        except AttributeError:
            result = result

        # ã‚¹ãƒšãƒ¼ã‚¹ã¨ä¸å¯è¦–æ–‡å­—ã‚’å‰Šé™¤
        try:
            result = _str_clean(result)
        except TypeError:
            result = result

    except:
        result = arg

    return result

# -------------------------------------------------------------------------------------
def normalization(arg):
    # print(2, arg)
    """
    æ–‡å­—åˆ—ã¾ãŸã¯æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã‚’æ­£è¦åŒ–ã™ã‚‹ã€‚
    """

    # å†…éƒ¨é–¢æ•°ã‚’NumPyã®ufuncã«å¤‰æ›
    _func = np.frompyfunc(_normalization, 1, 1)

    # ãƒªã‚¹ãƒˆã‚’NumPyé…åˆ—ã«å¤‰æ›
    _list = np.array(arg, dtype="object")

    # çµæžœã‚’å–å¾—
    result = _func(_list)

    # ãƒ‡ãƒ¼ã‚¿åž‹ã‚’å¤‰æ›
    result = result if type(result) == str else result.tolist() if type(result) == np.ndarray else "error"

    return result

# -------------------------------------------------------------------------------------
def _str_clean(arg):
    """
    æ–‡å­—åˆ—ã®ã‚¹ãƒšãƒ¼ã‚¹ã¨ä¸å¯è¦–æ–‡å­—ã‚’å‰Šé™¤ã™ã‚‹å†…éƒ¨é–¢æ•°ã€‚
    """

    try:
        result = arg.strip()
    except:
        result = arg

    try:
        result = re.sub(r"\r|\n|\r\n|\u3000|\t|ã€€| |,", " ", result)
    except TypeError:
        result = result

    return result

# -------------------------------------------------------------------------------------
def str_clean(arg):
    """
    æ–‡å­—åˆ—ã¾ãŸã¯æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã®ã‚¹ãƒšãƒ¼ã‚¹ã¨ä¸å¯è¦–æ–‡å­—ã‚’å‰Šé™¤ã™ã‚‹ã€‚
    """

    # å†…éƒ¨é–¢æ•°ã‚’NumPyã®ufuncã«å¤‰æ›
    _func = np.frompyfunc(_str_clean, 1, 1)

    # ãƒªã‚¹ãƒˆã‚’NumPyé…åˆ—ã«å¤‰æ›
    _list = np.array(arg, dtype="object")

    # çµæžœã‚’å–å¾—
    result = _func(_list)

    # ãƒ‡ãƒ¼ã‚¿åž‹ã‚’å¤‰æ›
    result = result if type(result) == str else result.tolist() if type(result) == np.ndarray else "error"

    return result

# -------------------------------------------------------------------------------------
def _split_buildingName(arg):
    # print(1, arg)
    """
    å»ºç‰©åã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹å†…éƒ¨é–¢æ•°ã€‚
    """
    ## ãƒã‚¤ãƒ•ãƒ³ã®ä¸€èˆ¬åŒ–
    address = normalization(arg)
    hyphens = '-Ë—á…³á­¸â€â€‘â€’â€“â€”â€•âƒâ»âˆ’â–¬â”€â”âž–ãƒ¼ã…¡ï¹˜ï¹£ï¼ï½°ð„ð†‘áš€'
    address = re.sub("|".join(hyphens), "-", address)
    address = re.sub(r"([ï½±-ï¾])(-)",r"\1ï½°", address)

    ## ä¸ç›®ã€ç•ªåœ°ã€å·ãªã©ã§ä½¿ã‚ã‚Œã‚‹æ¼¢å­—ã®å®šç¾©
    chome_poplist = ["ï¾‰åˆ‡","ç”ºç›®","åœ°å‰²","ä¸ç›®","ä¸","çµ„","ç•ªç”º","ç•ªåœ°","ç•ªç›®","ç•ª","å·å®¤","å·","è¡—åŒº","ç”»åœ°"]
    chome_popset = r"|".join(chome_poplist)
    chome_holdlist = ["æ¡æ±","æ¡è¥¿","æ¡å—","æ¡åŒ—","æ¡é€š","æ¡","æ±","è¥¿","å—","åŒ—"]
    chome_holdset = r"|".join(chome_holdlist)
    chome_alllist = chome_popset + chome_holdset
    chome_allset = r"|".join(chome_alllist)

    ## separate address
    result = re.findall(re.compile(f"(.*\d\[{chome_allset}\]*)|(\D+\[-\d\]+)|(.*)"), address)

    ## convert kanji into hyphen
    result = [[re.sub(f"(\d+)({chome_popset})", r"\1-", "".join(t)) for t in tl] for tl in result]

    ## concat all
    result = ["".join(t) for t in result]
    result = "".join(result)

    ## special case handling (1ï¾‰3 1åŒº1)
    result = re.sub(r"([^ï½±ï½°ï¾])(ï¾‰|ï½°)(\d)", r"\1-\3", result)
    result = re.sub(r"(\d)(åŒº)(\d)", r"\1-\3", result)
    result = re.sub("--", "-", result)

    ## separate into [japanese] + [number + hyphen] chunks
    result = re.findall(re.compile(f"(\D+[-\d]+[{chome_holdset}]*[-\d]+)|(\D+[-\d]+)|(.*)"), result)
    result = [t for t in ["".join(tl) for tl in result] if t != ""]
    # print(3, result)
    ## merge [number + hyphen] chunks
    try:
        result = [result[0]] + ["".join(result[1:])]
    except:
        result = result

    # 2åˆ—ç›®ãŒå˜ç‹¬ã€Œf, éšŽã€ã®ã¨ãã€1åˆ—ç›®ã®æœ«å°¾æ•°ã‚’2åˆ—ç›®ã¸ç§»å‹•
    if re.fullmatch(r"f|éšŽ", result[1]):
        result[1] = "".join(re.compile(r"\d+$").findall(result[0])) + result[1]
        result[0] = re.sub(r"\d+$", "", result[0])

    # 2åˆ—ç›®ã§ã€éšŽæ•°ãŒç•ªåœ°ã¨çµåˆã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã¨ãã€éšŽæ•°ã‚’1æ¡ã¨ã¿ãªã—ã€æ®‹ã‚Šã®æ•°å­—ã‚’ç•ªåœ°ã¨ã—ã¦1åˆ—ç›®ã¸ç§»å‹•
    if (re.fullmatch(r"\D+", result[0]) or re.search(r"-$", result[0])) and re.match(r"(\d*)(\d)(f|éšŽ)(\d*)", result[1]):
        result[1] = re.sub(r"(\d*)(\d)(f|éšŽ)(\d*)", r"\1,\2\3\4", result[1])
        result[0] = result[0] + result[1][:result[1].find(",")]
        result[1] = result[1][result[1].find(",")+1:]

    # æœ«å°¾ã®ãƒã‚¤ãƒ•ãƒ³ã‚’å‰Šé™¤
    result[0] = re.sub(r"-+$", "", result[0])

    return result



def start_driver():
    # Seleniumç”¨ã®ã‚¦ã‚§ãƒ–ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’åˆæœŸåŒ–ã—ã€ã•ã¾ã–ã¾ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§å®‰å®šã—ãŸæœ€é©ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã‚’å¾—ã‚‹ã€‚
    # Seleniumç”¨ã®Chromeãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¨­å®šã€‚
    options = webdriver.ChromeOptions()
    # ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãŸã‚ã«ãƒ–ãƒ©ã‚¦ã‚¶æ‹¡å¼µã‚’ç„¡åŠ¹ã«ã™ã‚‹ã€‚
    options.add_argument('--disable-extensions')
    # ãƒ–ãƒ©ã‚¦ã‚¶ã‚’æœ€å¤§åŒ–ã—ãŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§é–‹å§‹ã€‚å‚è€ƒ: https://stackoverflow.com/a/26283818/1689770
    options.add_argument('--start-maximized')
    # äº’æ›æ€§å‘ä¸Šã®ãŸã‚ã«ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’ç„¡åŠ¹ã«ã™ã‚‹ã€‚å‚è€ƒ: https://stackoverflow.com/a/50725918/1689770
    options.add_argument('--no-sandbox')
    # ã‚ˆã‚Šå®‰å®šã—ãŸå‹•ä½œã®ãŸã‚ã«ã“ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã€‚å‚è€ƒ: https://stackoverflow.com/a/50725918/1689770
    options.add_argument('--disable-dev-shm-usage')

    # ä¸»å‡¦ç†
    try:
        driver_path = ChromeDriverManager().install()
        service = Service(executable_path=driver_path)
        driver = webdriver.Chrome(service=service, options=options)

    except ValueError:
        # æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®Chromeãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’å–å¾—ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€‚
        url = r'https://googlechromelabs.github.io/chrome-for-testing/last-known-good-versions-with-downloads.json'
        response = requests.get(url)
        data_dict = response.json()
        latest_version = data_dict["channels"]["Stable"]["version"]

        driver_path = ChromeDriverManager(version=latest_version).install()
        service = Service(executable_path=driver_path)
        driver = webdriver.Chrome(service=service, options=options)

    except PermissionError:  # æš«å®šå‡¦ç† å‚è€ƒ: https://note.com/yuu________/n/n14d97c155e5e
        try:
            driver = webdriver.Chrome(service=Service(
                f'C:\\Users\\{USERNAME}\\.wdm\\drivers\\chromedriver\\win64\\116.0.5845.141\\chromedriver.exe'), options=options)
        except:
            driver = webdriver.Chrome(service=Service(
                f'C:\\Users\\{USERNAME}\\.wdm\\drivers\\chromedriver\\win64\\116.0.5845.140\\chromedriver.exe'), options=options)

    # ãƒ–ãƒ©ã‚¦ã‚¶ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æœ€å¤§åŒ–ã€‚
    driver.maximize_window()
    # ã‚¦ã‚§ãƒ–ãƒ‰ãƒ©ã‚¤ãƒã®å¾…æ©Ÿæ™‚é–“ã‚’è¨­å®šã€‚
    wait = WebDriverWait(driver, WAIT_SEC)
    return driver


def get_base_data(html):
    baseData = {}
    timeStamp = datetime.date.today()
    baseData['storename'] = html.find_element(By.ID, 'lblKikanName').text if len(
        html.find_elements(By.ID, 'lblKikanName')) > 0 else '-'
    baseData['updated_at'] = html.find_element(By.ID, 'lblLastUpdate').text.split(
        ' ')[0] if len(html.find_elements(By.ID, 'lblLastUpdate')) > 0 else '-'
    baseData['address'] = html.find_element(By.ID, 'lblLocationName').text if len(
        html.find_elements(By.ID, 'lblLocationName')) > 0 else '-'
    try:
        storeAddressNormalize = "".join(list(normalize(baseData['address']).values())[0:4])
        baseData['address_normalize_1'] = _split_buildingName(storeAddressNormalize)[0]
        baseData['address_normalize_2'] = _split_buildingName(storeAddressNormalize)[1]
    except:
        baseData['address_normalize_1'] = baseData['address_normalize_2'] = "na"
    baseData['founder_name'] = html.find_element(By.ID, 'lblKaisetsuName').text.replace(
        '\u3000', ' ') if len(html.find_elements(By.ID, 'lblKaisetsuName')) > 0 else '-'
    baseData['admin_name'] = html.find_element(By.ID, 'lblKanriName').text.replace(
        '\u3000', ' ') if len(html.find_elements(By.ID, 'lblKanriName')) > 0 else '-'
    
    baseData['timestamp'] = timeStamp
    try:
        department_spans = html.find_element(By.ID, 'tblBKamoku').find_elements(By.ID, 'lblKamokuName')
        print(department_spans)
        medical_department = "["
        for department_span in department_spans:
            medical_department += (department_span.text + ", ")
        medical_department += "]"
    except:
        medical_department = "na"

    baseData['medical_department'] = medical_department


    return baseData


def get_amenity_data(html):
    true_elements = html.find_elements(By.XPATH, "//td[text()='æœ‰ã‚Š']")
    span_elements = html.find_elements(By.XPATH, "//span[text()='æœ‰ã‚Š']")
    if len(span_elements) > 0:
        for s_el in span_elements:
            true_elements.append(s_el.find_element(By.XPATH, '..'))

    if len(true_elements) > 0:
        amenityData = []
        for t_el in true_elements:
            service = t_el.find_element(
                By.XPATH, "./preceding-sibling::td[1]").find_element(By.TAG_NAME, 'span').text
            amenityData.append(service)
    else:
        amenityData = 'na'

    return amenityData


def get_contents_data(html):
    contentsData = {}
    general_elements = []
    if len(html.find_elements(By.XPATH, "//span[contains(text(), 'æ­¯ç§‘é ˜åŸŸ')]")) > 0:
        general_ancestor = html.find_element(
            By.XPATH, "//span[contains(text(), 'æ­¯ç§‘é ˜åŸŸ')]").find_element(By.XPATH, './ancestor::table[1]')
        general_elements = general_ancestor.find_element(
            By.XPATH, "following-sibling::table").find_elements(By.ID, 'lblIryokinoName')
    if len(general_elements) > 0:
        general_dentistry = []
        for g_el in general_elements:
            general_dentistry.append(g_el.text)
    else:
        general_dentistry = 'na'
    contentsData['general_dentistry'] = general_dentistry

    oral_elements = []
    if len(html.find_elements(By.XPATH, "//span[contains(text(), 'å£è…”å¤–ç§‘é ˜åŸŸ')]")) > 0:
        oral_ancestor = html.find_element(
            By.XPATH, "//span[contains(text(), 'å£è…”å¤–ç§‘é ˜åŸŸ')]").find_element(By.XPATH, './ancestor::table[1]')
        oral_elements = oral_ancestor.find_element(
            By.XPATH, "following-sibling::table").find_elements(By.ID, 'lblIryokinoName')
    if len(oral_elements) > 0:
        oral_surgery = []
        for o_el in oral_elements:
            oral_surgery.append(o_el.text)
    else:
        oral_surgery = 'na'
    contentsData['oral_surgery'] = oral_surgery

    homecare_elements = []
    if len(html.find_elements(By.XPATH, "//span[contains(text(), 'åœ¨å®…åŒ»ç™‚') and @id='lblZaitakuiryo']")) > 0:
        homecare_elements = html.find_element(By.XPATH, "//span[contains(text(), 'åœ¨å®…åŒ»ç™‚') and @id='lblZaitakuiryo']").find_element(
            By.XPATH, "following-sibling::table").find_elements(By.ID, "lblZaitakuiryoName")
    if len(homecare_elements) > 0:
        homecare = []
        for h_el in homecare_elements:
            homecare.append(h_el.text)
    else:
        homecare = 'na'
    contentsData['homecare'] = homecare

    collaboration_elements = []
    if len(html.find_elements(By.XPATH, "//span[contains(text(), 'é€£æºã®æœ‰ç„¡') and @id='lblZaitakuiryo']")) > 0:
        collaboration_elements = html.find_element(By.XPATH, "//span[contains(text(), 'é€£æºã®æœ‰ç„¡') and @id='lblZaitakuiryo']").find_element(
            By.XPATH, "following-sibling::table").find_elements(By.ID, "lblZaitakuiryoName")
    if len(collaboration_elements) > 0:
        collaboration = []
        for c_el in collaboration_elements:
            collaboration.append(c_el.text)
    else:
        collaboration = 'na'
    contentsData['collaboration'] = collaboration

    return contentsData


def get_actual_data(html):
    actualData = {}
    if len(html.find_elements(By.XPATH, "//span[text()='æ­¯ç§‘åŒ»å¸«']")) > 0:
        dentist_ancestor = html.find_element(
            By.XPATH, "//span[text()='æ­¯ç§‘åŒ»å¸«']").find_element(By.XPATH, './ancestor::tr[@id="trJininhaichi"]')
        den_total = dentist_ancestor.find_element(By.ID, 'lblSoSouSu').text
        den_full = dentist_ancestor.find_element(By.ID, 'lblJoSouSu').text
        den_part = dentist_ancestor.find_element(By.ID, 'lblHjSouSu').text
        actualData['dentist'] = den_total+'|' + den_full + '|' + den_part
    else:
        actualData['dentist'] = 'na'

    if len(html.find_elements(By.XPATH, "//span[text()='æ­¯ç§‘è¡›ç”Ÿå£«']")) > 0:
        hygienist_ancestor = html.find_element(
            By.XPATH, "//span[text()='æ­¯ç§‘è¡›ç”Ÿå£«']").find_element(By.XPATH, './ancestor::tr[@id="trJininhaichi"]')
        hyg_total = hygienist_ancestor.find_element(By.ID, 'lblSoSouSu').text
        hyg_full = hygienist_ancestor.find_element(By.ID, 'lblJoSouSu').text
        hyg_part = hygienist_ancestor.find_element(By.ID, 'lblHjSouSu').text
        actualData['dental_hygienist'] = hyg_total + \
            '|' + hyg_full + '|' + hyg_part
    else:
        actualData['dental_hygienist'] = 'na'

    if len(html.find_elements(By.ID, "pnlGairaiKanjyasu")) > 0 and len(html.find_elements(By.ID, "tblGairaiKanjyasu")) > 0:
        actualData['day_patients'] = html.find_element(By.ID, "pnlGairaiKanjyasu").find_element(
            By.XPATH, 'table[@id="tblGairaiKanjyasu"]').find_element(By.TAG_NAME, 'tr').find_elements(By.TAG_NAME, 'td')[1].text
    else:
        actualData['day_patients'] = 'na'

    return actualData


def main():
    driver = start_driver()
    driver.maximize_window()

    index = 0
    for line in f:
        page = line.split(',')[0]
        url = line.split(',')[1]
        print(url)
        driver.get(url)
        data = {}

        baseData = get_base_data(driver)
        if baseData:
            btn_tabs = driver.find_elements(
                By.CSS_SELECTOR, 'a[class="DetailHyper"]')
            btn_tabs[1].click()

        amenityData = get_amenity_data(driver)
        if amenityData:
            btn_tabs = driver.find_elements(
                By.CSS_SELECTOR, 'a[class="DetailHyper"]')
            btn_tabs[3].click()

        contentsData = get_contents_data(driver)
        if contentsData:
            btn_tabs = driver.find_elements(
                By.CSS_SELECTOR, 'a[class="DetailHyper"]')
            btn_tabs[4].click()

        actualData = get_actual_data(driver)
        if actualData:
            data = [
                baseData['timestamp'],
                baseData['storename'],
                baseData['address'],
                baseData['address_normalize_1'],
                baseData['address_normalize_2'],
                baseData['updated_at'],
                url,
                'na',
                baseData['founder_name'],
                baseData['admin_name'],
                contentsData['general_dentistry'],
                contentsData['oral_surgery'],
                'na',
                'na',
                amenityData,
                'na',
                contentsData['homecare'],
                contentsData['collaboration'],
                actualData['dentist'],
                'na',
                'na',
                actualData['dental_hygienist'],
                actualData['day_patients'],
                'na',
                'na',
                page,
                baseData['medical_department']
            ]
            writer.writerow(data)

        index += 1
        print(index)

    fc.close()
    driver.close()
    time.sleep(5000)


if __name__ == '__main__':
    main()
